[dataset]
# tensor type (float or double)
tensor_type = float

root_dir  = /home/disk2t/data/JSRT
train_csv = config/jsrt_train.csv
valid_csv = config/jsrt_valid.csv
test_csv  = config/jsrt_test.csv

load_pixelwise_weight = False
# modality number
modal_num = 1

# data transforms
train_transform = [NormalizeWithMeanStd, LabelConvert, RandomCrop, LabelToProbability]
test_transform  = [NormalizeWithMeanStd]

NormalizeWithMeanStd_channels = [0]
NormalizeWithMeanStd_mean = None
NormalizeWithMeanStd_std  = None
NormalizeWithMeanStd_mask = False
NormalizeWithMeanStd_random_fill = False
NormalizeWithMeanStd_inverse     = False

LabelConvert_source_list = [0, 255]
LabelConvert_target_list = [0, 1]
LabelConvert_inverse = False

RandomCrop_output_size = [240, 240]
RandomCrop_foreground_focus = False
RandomCrop_foreground_ratio = None
RandomCrop_mask_label       = None
RandomCrop_inverse     = False

LabelToProbability_class_num = 2
LabelToProbability_inverse   = False

[network]
# this section gives parameters for network
# the keys may be different for different networks

# type of network
net_type = UNet2D

# number of class, required for segmentation task
class_num = 2

in_chns       = 1
feature_chns  = [4, 16, 32, 64, 128]
dropout       = [0,  0,  0.3, 0.4, 0.5]
bilinear      = False

[training]
# device name" cuda:n or cpu
device_name = cuda:0

batch_size    = 4
loss_type     = DiceLoss
DiceLoss_enable_pixel_weight = False
DiceLoss_enable_class_weight = False

# for optimizers
optimizer     = Adam
learning_rate = 1e-3
momentum      = 0.9
weight_decay  = 1e-5

# for lr schedular (MultiStepLR)
lr_gamma      = 0.1
lr_milestones = [2000]

summary_dir       = model/unet_dice_loss
checkpoint_prefix = model/unet_dice_loss/unet

# start iter
iter_start = 0
iter_max   = 4000
iter_valid = 100
iter_save  = 2000

[testing]
# device name" cuda:n or cpu
device_name = cuda:0

checkpoint_name   = model/unet_dice_loss/unet_4000.pt
output_dir        = result
evaluation_mode   = True
test_time_dropout = False

mini_batch_size         = None
mini_patch_input_shape  = None
mini_patch_output_shape = None
mini_patch_stride       = None

# convert the label of prediction output
label_source = [0, 1]
label_target = [0, 255]
