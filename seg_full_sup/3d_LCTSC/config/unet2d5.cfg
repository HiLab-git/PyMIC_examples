[dataset]
# tensor type (float or double)
tensor_type = float

task_type = seg
train_dir = ../../PyMIC_data/LCTSC2017
train_csv = config/image_train.csv
valid_csv = config/image_valid.csv
test_csv  = config/image_test.csv

# modality number
modal_num = 1
train_batch_size = 2
num_worker = 4

patch_size       = [64, 128, 128]
# data transforms
train_transform = [Pad, RandomCrop, NormalizeWithMinMax, RandomFlip, LabelToProbability]
valid_transform = [Pad, NormalizeWithMinMax, LabelToProbability]
test_transform  = [Pad, NormalizeWithMinMax]

NormalizeWithMinMax_channels        = [0]
NormalizeWithMinMax_threshold_lower = [-1000]
NormalizeWithMinMax_threshold_upper = [1000]

RandomFlip_flip_depth  = False
RandomFlip_flip_height = False
RandomFlip_flip_width  = True

LabelToProbability_class_num = 5

[network]
# type of network
net_type = UNet2D5

# number of class, required for segmentation task
class_num = 5

in_chns       = 1
feature_chns  = [32, 64, 128, 256, 512]
dropout       = [0, 0, 0.2, 0.2, 0.2]
conv_dims     = [2, 2, 3, 3, 3]

[training]
# list of gpus
gpus       = [0]


loss_type     = DiceLoss

# for optimizers
optimizer     = Adam
learning_rate = 1e-3
momentum      = 0.9
weight_decay  = 1e-5


# for lr schedular (StepLR)
lr_scheduler = StepLR
lr_gamma = 0.5
lr_step  = 4000
early_stop_patience = 6000
ckpt_dir            = model/unet2d5

# start iter
iter_max   = 10000
iter_valid = 250
iter_save  = 10000

[testing]
# list of gpus
gpus       = [0]

ckpt_mode         = 1
output_dir        = result/unet2d5

sliding_window_enable = True
sliding_window_batch  = 4
sliding_window_size   = [64, 128, 128]
sliding_window_stride = [32, 64, 64]

