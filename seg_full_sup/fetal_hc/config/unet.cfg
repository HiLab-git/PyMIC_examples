[dataset]
# tensor type (float or double)
tensor_type = float

task_type = seg
train_dir = ../../PyMIC_data/Fetal_HC
train_csv = config/fetal_hc_train.csv
valid_csv = config/fetal_hc_valid.csv
test_csv  = config/fetal_hc_test.csv

train_batch_size = 4

# data transforms
train_transform = [Rescale, RandomCrop, RandomFlip, NormalizeWithMeanStd, LabelConvert, LabelToProbability]
valid_transform = [Rescale, NormalizeWithMeanStd, LabelConvert, LabelToProbability]
test_transform  = [Rescale, NormalizeWithMeanStd]

Rescale_output_size    = [256, 384]
RandomCrop_output_size = [224, 320]

RandomFlip_flip_depth  = False
RandomFlip_flip_height = True
RandomFlip_flip_width  = True

NormalizeWithMeanStd_channels = [0]

LabelConvert_source_list = [0, 255]
LabelConvert_target_list = [0, 1]

[network]
# type of network
net_type = UNet2D

# number of class, required for segmentation task
class_num = 2
in_chns       = 1
feature_chns  = [16, 32, 64, 128, 256]
dropout       = [0.0,  0.0,  0.3, 0.4, 0.5]

[training]
# list of gpus
gpus = [0]

loss_type     = [DiceLoss, CrossEntropyLoss]
loss_weight   = [1.0, 1.0]

# for optimizers
optimizer     = Adam
learning_rate = 1e-3
momentum      = 0.9
weight_decay  = 1e-5

# for lr schedular  
lr_scheduler  = ReduceLROnPlateau
lr_gamma      = 0.5
ReduceLROnPlateau_patience = 2000
early_stop_patience = 5000

ckpt_save_dir    = model/unet

# start iter
iter_start = 0
iter_max   = 15000
iter_valid = 100
iter_save  = 5000

[testing]
# list of gpus
gpus       = [0]

# checkpoint mode can be [0-latest, 1-best, 2-specified]
ckpt_mode  = 0
output_dir = result

# use test time augmentation
tta_mode = 0

sliding_window_enable = True
sliding_window_size   = [224, 320]
sliding_window_stride = [224, 320]

# convert the label of prediction output
label_source = [0, 1]
label_target = [0, 255]
