[dataset]
# tensor type (float or double)
tensor_type = float

task_type = seg
train_dir = ../../PyMIC_data/ACDC/preprocess/
train_csv = config/data/image_train.csv
valid_csv = config/data/image_valid.csv
test_csv  = config/data/image_test.csv

train_batch_size = 4

# data transforms
train_transform = [NormalizeWithMeanStd, Pad, RandomFlip,  RandomCrop, LabelToProbability]
valid_transform = [NormalizeWithMeanStd, Pad, LabelToProbability]
test_transform  = [NormalizeWithMeanStd, Pad]


NormalizeWithMeanStd_channels = [0]

RandomFlip_flip_depth  = False
RandomFlip_flip_height = True
RandomFlip_flip_width  = True

RandomCrop_output_size = [8, 256, 256]
RandomCrop_foreground_focus = True
RandomCrop_foreground_ratio = 0.5
Randomcrop_mask_label       = [1, 2, 3]

Pad_output_size = [8, 256, 256]
Pad_ceil_mode   = False

[network]
# this section gives parameters for network
# the keys may be different for different networks

# type of network
net_type = TransUNet

# number of class, required for segmentation task
class_num     = 4
img_size      = [256, 256]

[training]
# list of gpus
gpus       = [0]

loss_type     = DiceLoss

# for optimizers
optimizer     = Adam
learning_rate = 1e-3
momentum      = 0.9
weight_decay  = 1e-5

# for lr schedular (StepLR)
lr_scheduler  = StepLR
lr_gamma      = 0.5
lr_step       = 5000
early_stop_patience = 10000

ckpt_dir    = model/transunet

# start iter
iter_max   = 15000
iter_valid = 250
iter_save  = 15000

[testing]
# list of gpus
gpus       = [0]

# checkpoint mode can be [0-latest, 1-best, 2-specified]
ckpt_mode         = 1
output_dir        = result/transunet

sliding_window_enable = True
sliding_window_batch  = 2
sliding_window_size   = [8, 256, 256]
sliding_window_stride = [8, 256, 256]

