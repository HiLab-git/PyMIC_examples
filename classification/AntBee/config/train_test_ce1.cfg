[dataset]
# tensor type (float or double)
tensor_type = float

task_type = cls
root_dir  = ../../PyMIC_data/hymenoptera_data
train_csv = config/train_data.csv
valid_csv = config/valid_data.csv
test_csv  = config/valid_data.csv

train_batch_size = 4

# modality number
modal_num = 1

# data transforms
train_transform = [Rescale, RandomCrop, RandomFlip, NormalizeWithMeanStd, LabelToProbability]
valid_transform = [Rescale, CenterCrop, NormalizeWithMeanStd, LabelToProbability]
test_transform  = [Rescale, CenterCrop, NormalizeWithMeanStd]

Rescale_output_size    = [256, 256]
RandomCrop_output_size = [224, 224]
CenterCrop_output_size = [224, 224]

RandomFlip_flip_depth  = False
RandomFlip_flip_height = False
RandomFlip_flip_width  = True

NormalizeWithMeanStd_channels = [0, 1, 2]
NormalizeWithMeanStd_mean = [123.675, 116.28, 103.53]
NormalizeWithMeanStd_std  = [58.395, 57.12, 57.375]

[network]
# this section gives parameters for network
# the keys may be different for different networks

# type of network
net_type   = resnet18
pretrain   = True
input_chns = 3
# finetune all the layers
update_mode = all

# number of classes
class_num = 2

[training]
# list of gpus
gpus       = [0]

loss_type     = CrossEntropyLoss

# for optimizers
optimizer     = SGD
learning_rate = 1e-3
momentum      = 0.9
weight_decay  = 1e-5

# for lr schedular (StepLR)
lr_scheduler = StepLR
lr_gamma     = 0.5
lr_step      = 500

ckpt_dir = model/resnet18_ce1
ckpt_prefix   = resnet18

# iteration
iter_start = 0
iter_max   = 2000
iter_valid = 100
iter_save  = 2000
early_stop_patience = 1000

[testing]
# list of gpus
gpus        = [0]

# checkpoint mode can be [0-latest, 1-best, 2-specified]
ckpt_mode        = 1
output_dir       = result
output_csv       = resnet18_ce1.csv
save_probability = True
