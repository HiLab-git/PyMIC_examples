[dataset]
# tensor type (float or double)
tensor_type    = float
task_type      = rec
supervise_type = self_sup

# Set this value according to the path of dataset
train_dir = /home/disk4t/data/lung/LUNA2016/preprocess
valid_dir = ./pretrain_valid/patchswap
test_dir  = ./pretrain_valid/patchswap
train_csv = config/luna_data/luna_train.csv
valid_csv = config/luna_data/luna_valid.csv
test_csv  = config/luna_data/luna_valid.csv

train_batch_size = 2
num_worker       = 4
patch_size       = [64, 128, 128]

train_transform = [RandomCrop, PatchSwaping]
valid_transform = None
test_transform  = None

RandomCrop_output_size  = [64, 128, 128]

PatchSwaping_block_range = [20, 40]
PatchSwaping_block_size  = [8, 16, 16]

[network]
# type of network
net_type = UNet3D

# number of class, required for segmentation task
class_num     = 1
in_chns       = 1
feature_chns  = [32, 64, 128, 256, 512]
dropout       = [0, 0, 0.2, 0.2, 0.2]
up_mode       = 2
multiscale_pred = False

[self_supervised_learning]
method_name = PatchSwapping

[training]
# list of gpus
gpus       = [0]

loss_type     = MAELoss
loss_acti_func  = tanh

# for optimizers
optimizer     = Adam
learning_rate = 1e-3
momentum      = 0.9
weight_decay  = 1e-5

# for lr schedular
lr_scheduler = StepLR
lr_gamma = 0.5
lr_step  = 40000
early_stop_patience = 80000
ckpt_save_dir       = model/unet3d_patchswap_pretrain

iter_max   = 120000
iter_valid = 500
iter_save  = 40000

[testing]
# list of gpus
gpus       = [0]

# checkpoint mode can be [0-latest, 1-best, 2-specified]
ckpt_mode         = 1
output_dir        = result_self_sup/unet3d_patchswap_pretrain
post_process      = None
sliding_window_enable = False