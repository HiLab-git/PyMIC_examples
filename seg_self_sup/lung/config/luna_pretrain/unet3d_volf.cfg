[dataset]
# tensor type (float or double)
tensor_type    = float
task_type      = seg
supervise_type = self_sup

# Set this value according to the path of dataset
train_dir = /home/disk4t/data/lung/LUNA2016/preprocess
valid_dir = ./pretrain_valid/volumefusion
test_dir  = ./pretrain_valid/volumefusion
train_csv = config/luna_data/luna_train.csv
valid_csv = config/luna_data/luna_valid.csv
test_csv  = config/luna_data/luna_valid.csv

train_batch_size = 2
num_worker       = 4
patch_size       = [64, 128, 128]

train_transform = [Crop4VolumeFusion, VolumeFusion, LabelToProbability]
valid_transform = [CenterCrop, LabelToProbability]
test_transform  = None

Crop4VolumeFusion_output_size = [64, 128, 128]
VolumeFusion_cls_num = 5
VolumeFusion_foreground_ratio = 0.7
VolumeFusion_patchsize_min    = [5, 8, 8]
VolumeFusion_patchsize_max    = [20, 32, 32]

[network]
# type of network
net_type = UNet3D

# number of class, required for segmentation task
class_num     = 5
in_chns       = 1
feature_chns  = [32, 64, 128, 256, 512]
dropout       = [0, 0, 0.2, 0.2, 0.2]
up_mode       = 2
multiscale_pred = False

[self_supervised_learning]
method_name = VolumeFusion

[training]
# list of gpus
gpus       = [0]

loss_type     = [DiceLoss, CrossEntropyLoss]
loss_weight   = [0.5, 0.5]

# for optimizers
optimizer     = Adam
learning_rate = 1e-3
momentum      = 0.9
weight_decay  = 1e-5

# for lr schedular
lr_scheduler = StepLR
lr_gamma = 0.5
lr_step  = 20000
early_stop_patience = 20000
ckpt_dir       = pretrain_model/unet3d_volf

iter_max   = 80000
iter_valid = 1000
iter_save  = 40000

[testing]
# list of gpus
gpus       = [0]
evaluation_mode   = True
sliding_window_enable = False